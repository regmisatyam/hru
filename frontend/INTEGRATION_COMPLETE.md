# âœ… Dual Backend Integration - Complete

## ğŸ‰ What Changed

Your project now has a **clear separation** between two backend services:

### Before:
- âŒ Confusing single `VITE_API_BASE_URL` variable
- âŒ Unclear which endpoints go where
- âŒ MediaPipe and Gemini on same port

### After:
- âœ… **MediaPipe Backend (8001)**: Face detection, WebSocket, TTS
- âœ… **Gemini Backend (8002)**: AI coaching, session insights
- âœ… Clear environment variables for each service
- âœ… All components updated to use correct URLs

## ğŸ“‹ Files Modified

### Environment Configuration
- âœ… `.env` - Split into `VITE_MEDIAPIPE_API_URL` and `VITE_GEMINI_API_URL`
- âœ… `.env.example` - Updated documentation

### Frontend Components
- âœ… `Session.tsx` - Now uses both `MEDIAPIPE_API_URL` and `GEMINI_API_URL`
- âœ… `StudyDebrief.tsx` - Uses `GEMINI_API_URL`

### Documentation
- âœ… `API_SETUP.md` - Updated with dual-backend instructions
- âœ… `ARCHITECTURE.md` - **NEW** - Complete system design
- âœ… `QUICK_REFERENCE.md` - **NEW** - Quick troubleshooting guide

### Backend (Already Created)
- âœ… `src/api/server.ts` - Gemini Express server on port 8002

## ğŸŒ API Endpoint Distribution

### MediaPipe Backend (Port 8001) - External Python Server
```
WebSocket /ws/study           â†’ Real-time video frame processing
GET      /ai-messages         â†’ Vibe-based motivational messages  
POST     /session/api/tts     â†’ Text-to-speech audio generation
```

### Gemini Backend (Port 8002) - TypeScript Server in `src/api/`
```
GET      /health              â†’ Health check & Gemini status
POST     /api/micro-nudge     â†’ AI-generated coaching tips
POST     /api/study-debrief   â†’ Session analysis & insights
POST     /api/feedback        â†’ False-positive corrections
```

## ğŸš€ Running the Full Stack

### Option 1: Recommended (Concurrent)
```bash
# Terminal 1 - Frontend + Gemini Backend
npm run dev:all

# Terminal 2 - MediaPipe Backend  
cd ../backend && python main.py
```

### Option 2: Individual Terminals
```bash
# Terminal 1 - Frontend
npm run dev

# Terminal 2 - Gemini Backend
npm run dev:api

# Terminal 3 - MediaPipe Backend
cd ../backend && python main.py
```

## âœ… Verification Checklist

Run these tests to verify everything works:

```bash
# 1. Check Gemini Backend is running
curl http://localhost:8002/health
# Expected: {"status":"healthy","geminiConfigured":true}

# 2. Check MediaPipe Backend is running
curl http://localhost:8001/ai-messages?vibe=calm&duration=25
# Expected: {"message":"Some motivational text..."}

# 3. Test Gemini micro-nudge endpoint
curl -X POST http://localhost:8002/api/micro-nudge \
  -H "Content-Type: application/json" \
  -d '{"distraction_count":3,"vibe":"calm","session_duration":300,"recent_events":[]}'
# Expected: {"nudge":{"type":"breathing","message":"..."}}

# 4. Check frontend environment variables
# Open browser console on http://localhost:5173
# Type: console.log(import.meta.env)
# Should see: VITE_MEDIAPIPE_API_URL and VITE_GEMINI_API_URL
```

## ğŸ” Environment Variables Reference

```env
# .env file structure

# MediaPipe Backend (Face Detection & WebSocket)
VITE_MEDIAPIPE_API_URL=http://localhost:8001

# Gemini AI Backend (Chat & Insights)
VITE_GEMINI_API_URL=http://localhost:8002
GEMINI_API_KEY=AIzaSyCH3pcVGHt8j_LYIVBJN2ZT4VflQqUX0p0
PORT=8002
```

### Variable Usage

| Variable | Used By | Purpose |
|----------|---------|---------|
| `VITE_MEDIAPIPE_API_URL` | Frontend | Connect to MediaPipe backend (8001) |
| `VITE_GEMINI_API_URL` | Frontend | Connect to Gemini backend (8002) |
| `GEMINI_API_KEY` | Gemini Backend | Authenticate with Google AI |
| `PORT` | Gemini Backend | Which port to run on |

**Note:** Variables starting with `VITE_` are accessible in frontend via `import.meta.env`

## ğŸ“Š Data Flow Examples

### Example 1: Real-time Focus Tracking
```
User's webcam â†’ Session.tsx
     â†“
VideoFrame â†’ WebSocket â†’ MEDIAPIPE_API_URL:8001/ws/study
     â†“
MediaPipe processes face/eye detection
     â†“
Focus score â† Session.tsx
     â†“
UI updates with real-time score
```

### Example 2: AI Coaching (Micro-Nudge)
```
Session.tsx detects 3 distractions in 2 minutes
     â†“
POST â†’ GEMINI_API_URL:8002/api/micro-nudge
     â†“
Gemini AI analyzes patterns + vibe
     â†“
Returns personalized tip (breathing/posture/stretch)
     â†“
MicroNudge.tsx displays notification
```

### Example 3: Post-Session Analysis
```
User ends session â†’ Session.tsx saves to localStorage
     â†“
Navigate to PostSession.tsx
     â†“
StudyDebrief.tsx loads session data
     â†“
POST â†’ GEMINI_API_URL:8002/api/study-debrief
     â†“
Gemini analyzes: distractions, focus score, vibe
     â†“
Returns: summary, strengths, triggers, action plan
     â†“
UI displays analysis + false-positive correction
```

## ğŸ¯ Next Steps

1. âœ… **Dependencies installed** - `npm install` already run
2. âœ… **Environment configured** - `.env` has both URLs
3. âœ… **Code updated** - All components use correct backends
4. ğŸ”„ **Test the system**:
   - Start both backends
   - Open http://localhost:5173
   - Start a study session
   - Verify WebSocket connection (MediaPipe)
   - Trigger micro-nudges (Gemini)
   - Complete session and check debrief (Gemini)

## ğŸ“š Documentation Map

- **Getting Started** â†’ `README.md` (if exists) or `API_SETUP.md`
- **System Design** â†’ `ARCHITECTURE.md` (detailed architecture)
- **Quick Help** â†’ `QUICK_REFERENCE.md` (troubleshooting)
- **API Specs** â†’ `API_SETUP.md` (endpoint documentation)
- **Features** â†’ `FEATURES_SUMMARY.md` (feature implementation)

## ğŸŠ Summary

Your Gemini API is now properly integrated as a **separate backend service** running on **port 8002** inside your project at `src/api/server.ts`. It works alongside the MediaPipe backend (port 8001) to provide:

- **Real-time AI coaching** during study sessions
- **Personalized session insights** after completion  
- **Strengths-based reflection** with actionable habits

All frontend components have been updated to call the correct backend for each feature. The architecture is now clean, scalable, and easy to debug! ğŸš€
