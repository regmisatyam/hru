# Focus-Bolt Architecture Overview

## üèóÔ∏è System Architecture

This project uses a **dual-backend architecture** to separate concerns:

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                     Frontend (React + Vite)                 ‚îÇ
‚îÇ                     Port: 5173                              ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ  Components:                                        ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - Session.tsx (Main study session)                 ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - MicroNudge.tsx (Real-time notifications)        ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - StudyDebrief.tsx (Post-session analysis)        ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ            ‚îÇ                                  ‚îÇ             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
             ‚îÇ                                  ‚îÇ
             ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                  ‚îÇ
             ‚îÇ              ‚îÇ                  ‚îÇ
             ‚ñº              ‚ñº                  ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  MediaPipe Backend ‚îÇ  ‚îÇ      Gemini AI Backend (TS)        ‚îÇ
‚îÇ  Port: 8001        ‚îÇ  ‚îÇ      Port: 8002                    ‚îÇ
‚îÇ  (External)        ‚îÇ  ‚îÇ      src/api/server.ts             ‚îÇ
‚îÇ                    ‚îÇ  ‚îÇ                                    ‚îÇ
‚îÇ  Endpoints:        ‚îÇ  ‚îÇ  Endpoints:                        ‚îÇ
‚îÇ  - /ws/study       ‚îÇ  ‚îÇ  - /api/micro-nudge                ‚îÇ
‚îÇ  - /ai-messages    ‚îÇ  ‚îÇ  - /api/study-debrief              ‚îÇ
‚îÇ  - /session/api/tts‚îÇ  ‚îÇ  - /api/feedback                   ‚îÇ
‚îÇ                    ‚îÇ  ‚îÇ                                    ‚îÇ
‚îÇ  Handles:          ‚îÇ  ‚îÇ  Handles:                          ‚îÇ
‚îÇ  ‚Ä¢ Face detection  ‚îÇ  ‚îÇ  ‚Ä¢ AI-generated coaching tips      ‚îÇ
‚îÇ  ‚Ä¢ Eye tracking    ‚îÇ  ‚îÇ  ‚Ä¢ Session analysis & insights     ‚îÇ
‚îÇ  ‚Ä¢ Focus scoring   ‚îÇ  ‚îÇ  ‚Ä¢ Personalized recommendations    ‚îÇ
‚îÇ  ‚Ä¢ WebSocket       ‚îÇ  ‚îÇ  ‚Ä¢ Feedback collection             ‚îÇ
‚îÇ    frames          ‚îÇ  ‚îÇ                                    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## üì° API Endpoint Mapping

### MediaPipe Backend (Port 8001)
**Environment Variable:** `VITE_MEDIAPIPE_API_URL`

| Endpoint | Method | Purpose | Used By |
|----------|--------|---------|---------|
| `/ws/study` | WebSocket | Real-time video frame processing & focus scoring | Session.tsx |
| `/ai-messages` | GET | Vibe-based motivational messages | Session.tsx |
| `/session/api/tts` | POST | Text-to-speech audio generation | Session.tsx |

### Gemini AI Backend (Port 8002)
**Environment Variable:** `VITE_GEMINI_API_URL`

| Endpoint | Method | Purpose | Used By |
|----------|--------|---------|---------|
| `/api/micro-nudge` | POST | AI-generated real-time coaching tips | Session.tsx |
| `/api/study-debrief` | POST | Post-session analysis & reflection | StudyDebrief.tsx |
| `/api/roadmap` | POST | Learning roadmap generation | Roadmap.tsx |
| `/api/feedback` | POST | False-positive correction data | StudyDebrief.tsx |
| `/health` | GET | Health check & Gemini status | - |

## üîÑ Data Flow Examples

### 1. Real-time Focus Tracking
```
User sits at camera
      ‚Üì
Session.tsx captures video frames
      ‚Üì
Frames sent via WebSocket ‚Üí MediaPipe Backend (8001)
      ‚Üì
MediaPipe processes face/eye detection
      ‚Üì
Focus score returned to frontend
      ‚Üì
UI updates with real-time score
```

### 2. Micro-Nudge Generation
```
Session.tsx detects 3 distractions in 2 minutes
      ‚Üì
POST request ‚Üí Gemini Backend (8002) /api/micro-nudge
      ‚Üì
Gemini AI analyzes distraction patterns + vibe
      ‚Üì
Returns personalized coaching tip
      ‚Üì
MicroNudge.tsx displays notification
```

### 3. Post-Session Analysis
```
User ends study session
      ‚Üì
Session.tsx saves data to localStorage
      ‚Üì
Navigate to PostSession.tsx
      ‚Üì
StudyDebrief.tsx loads session data
      ‚Üì
POST request ‚Üí Gemini Backend (8002) /api/study-debrief
      ‚Üì
Gemini analyzes full session (distractions, focus score, vibe)
      ‚Üì
Returns strengths-based reflection + action plan
      ‚Üì
UI displays analysis + false-positive correction interface
```

## üîê Environment Configuration

### `.env` File Structure
```env
# MediaPipe Backend (Face Detection & WebSocket)
VITE_MEDIAPIPE_API_URL=http://localhost:8001

# Gemini AI Backend (Chat & Insights)
VITE_GEMINI_API_URL=http://localhost:8002
GEMINI_API_KEY=your_actual_gemini_api_key_here
PORT=8002
```

### Frontend Access
```typescript
// In React components:
const MEDIAPIPE_API_URL = import.meta.env.VITE_MEDIAPIPE_API_URL;
const GEMINI_API_URL = import.meta.env.VITE_GEMINI_API_URL;
```

### Backend Access
```typescript
// In Express server:
const GEMINI_API_KEY = process.env.GEMINI_API_KEY;
const PORT = process.env.PORT || 8002;
```

## üöÄ Running the Full Stack

### Option 1: All-in-One Command (Recommended)
```bash
npm run dev:all
```
This runs:
- Frontend on `http://localhost:5173`
- Gemini Backend on `http://localhost:8002`
- **Note:** MediaPipe backend (8001) must be started separately

### Option 2: Individual Terminals
```bash
# Terminal 1 - Frontend
npm run dev

# Terminal 2 - Gemini Backend
npm run dev:api

# Terminal 3 - MediaPipe Backend (external)
cd ../backend && python main.py
```

## üì¶ Dependencies by Service

### Frontend (package.json)
- `react` - UI framework
- `axios` - HTTP client for API calls
- `recharts` - Session analytics charts
- `lucide-react` - Icon library
- `tailwindcss` - Styling

### Gemini Backend (package.json)
- `express` - Web server
- `@google/generative-ai` - Gemini AI SDK
- `cors` - Cross-origin requests
- `dotenv` - Environment variables
- `tsx` - TypeScript execution

### MediaPipe Backend (External - Python)
- `fastapi` - API framework
- `mediapipe` - Computer vision
- `opencv-python` - Video processing
- `websockets` - Real-time communication

## üé® Component Responsibilities

### Session.tsx
- **Purpose:** Main study session interface
- **APIs Used:** Both MediaPipe (8001) & Gemini (8002)
- **Key Features:**
  - WebSocket video streaming to MediaPipe
  - Real-time focus score display
  - Distraction pattern detection
  - Micro-nudge triggering (Gemini)
  - Session data persistence (localStorage)

### MicroNudge.tsx
- **Purpose:** Real-time notification overlay
- **APIs Used:** None (receives data from parent)
- **Key Features:**
  - Three nudge types (breathing, posture, stretch)
  - Liquid glass morphism design
  - Auto-dismiss with progress bar
  - Vibe-aware styling

### StudyDebrief.tsx
- **Purpose:** Post-session AI reflection
- **APIs Used:** Gemini (8002)
- **Key Features:**
  - AI-generated session summary
  - Strengths identification
  - Trigger pattern analysis
  - Actionable habit recommendations
  - False-positive correction UI
  - Feedback submission

## üîß Development Workflow

### Adding a New Feature

1. **Determine which backend to use:**
   - Computer vision / Real-time processing ‚Üí MediaPipe (8001)
   - AI analysis / Text generation ‚Üí Gemini (8002)

2. **Create endpoint (if Gemini feature):**
   ```typescript
   // In src/api/server.ts
   app.post('/api/new-feature', async (req: Request, res: Response) => {
     // Use Gemini AI here
   });
   ```

3. **Call from frontend:**
   ```typescript
   const GEMINI_API_URL = import.meta.env.VITE_GEMINI_API_URL;
   const response = await axios.post(`${GEMINI_API_URL}/api/new-feature`, data);
   ```

### Testing APIs

```bash
# Test Gemini Backend health
curl http://localhost:8002/health

# Test micro-nudge
curl -X POST http://localhost:8002/api/micro-nudge \
  -H "Content-Type: application/json" \
  -d '{"distraction_count": 3, "vibe": "calm"}'

# Test MediaPipe Backend
curl http://localhost:8001/ai-messages?vibe=calm&duration=25
```

## üîç Debugging Tips

### Frontend Issues
- Check browser console for API errors
- Verify environment variables: `console.log(import.meta.env)`
- Use Network tab to inspect requests

### Gemini Backend Issues
- Check server logs in terminal running `npm run dev:api`
- Verify API key: Server logs will show warning if missing
- Test endpoints with cURL before frontend integration

### MediaPipe Backend Issues
- Ensure Python backend is running on correct port
- Check WebSocket connection status in Session.tsx
- Verify camera permissions in browser

## üìä Performance Considerations

- **WebSocket frames:** Sent at 10 FPS to balance performance
- **Micro-nudge cooldown:** Prevents spam notifications
- **Gemini API calls:** Cached/fallback responses for failures
- **Session data:** Stored in localStorage, not database

## üõ°Ô∏è Security Notes

- ‚úÖ `.env` is gitignored (API keys protected)
- ‚úÖ CORS limited to localhost during development
- ‚úÖ No user video uploaded to any server
- ‚úÖ MediaPipe runs locally (privacy-first)
- ‚ö†Ô∏è Production: Update CORS, use HTTPS, add rate limiting
